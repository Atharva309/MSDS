{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "355204281a246ade67e9ff97fefea25e",
     "grade": false,
     "grade_id": "cell-156071440cc41234",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Classification using TidyModels\n",
    "\n",
    "In this lab we would be going through:\n",
    "- Logistic Regression\n",
    "- Linear Discriminant Analysis\n",
    "- Quadratic Discriminant Analysis\n",
    "\n",
    "using TidyModels. \n",
    "\n",
    "For this lab, we would examining the `OJ` data set that contains a number of numeric variables plus a variable called `Purchase` which has the two labels `CH` and `MM` (which is Citrus Hill or Minute Maid Orange Juice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06b8d7d28f408550c86889f5c82cdc09",
     "grade": false,
     "grade_id": "cell-17529ea80e2b7b9a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages(library(tidymodels))\n",
    "suppressPackageStartupMessages(library(ISLR))\n",
    "suppressPackageStartupMessages(library(discrim))\n",
    "suppressPackageStartupMessages(library(corrr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(OJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "287d78cd7035832f460ce027572fc548",
     "grade": false,
     "grade_id": "cell-2ea3a28585c3f9d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "attach(OJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1581d502d6d10acfe458ebab743c8121",
     "grade": false,
     "grade_id": "cell-aa0613238becdb63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The `correlate()` function (from `corrr` package) will calculate the correlation matrix between all the variables that it is being fed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea6fc8e317822a054d5284d9bd3bd2a6",
     "grade": false,
     "grade_id": "cell-9d60d2656c19ccde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cor_oj <- OJ %>%\n",
    "  select(-Purchase, -Store7) %>% #Remove Purchase & Store as it not numeric\n",
    "  correlate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8092bd09af8c4ebca7171a41c6ca910d",
     "grade": false,
     "grade_id": "cell-2e5fdd7a0012667f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Lets pass this correlation to `rplot()` to visualize the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9991d269dd2ff3d45f3ff1fe319db594",
     "grade": false,
     "grade_id": "cell-b76a19b4a00b3e39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "rplot(cor_oj, colours = c(\"indianred2\", \"black\", \"skyblue1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dbe8bad0b144caa576733f78762bd71",
     "grade": false,
     "grade_id": "cell-c5617ac92a9248cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Now we will fit a logistic regression model. We will again use the `parsnip` package, and we will use `logistic_reg()` to create a logistic regression model specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcde6e19853de1f0197689c08e5d1f1b",
     "grade": false,
     "grade_id": "cell-8ef12e262df657c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lr_spec <- logistic_reg() %>%\n",
    "  set_engine(\"glm\") %>% #default engine\n",
    "  set_mode(\"classification\") #default mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f1d13c064dbdcd88098d0e6b0cd2a6e",
     "grade": false,
     "grade_id": "cell-52bcfa4c17a16dfc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We want to model the `Direction` of the stock market based on the percentage return from the 5 previous days plus the volume of shares traded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "caf7846aea374ad656dc546b23222d77",
     "grade": false,
     "grade_id": "cell-aa33bdb287109e7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lr_fit <- lr_spec %>%\n",
    "  fit(\n",
    "    Purchase ~ PriceCH + PriceMM + SalePriceMM + SalePriceCH + WeekofPurchase,\n",
    "    data = OJ\n",
    "    )\n",
    "\n",
    "lr_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd0054cb4bbb1af3893831ec9f7e4a85",
     "grade": false,
     "grade_id": "cell-32608671d1f569f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lr_fit %>%\n",
    "  pluck(\"fit\") %>%\n",
    "  summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b327fe065f902c80fcf91c2614c2d01b",
     "grade": false,
     "grade_id": "cell-5bc863a496b67303",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The `summary()` lets us see a couple of different things such as; parameter estimates, standard errors, p-values, and model fit statistics. \n",
    "\n",
    "we can use the `tidy()` function to extract some of these model attributes for further analysis or presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3703f3407d6dba9df7e389a2f50959a",
     "grade": false,
     "grade_id": "cell-a00548e6c141ebb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tidy(lr_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22d9db7692c2589c64292d8f991e8475",
     "grade": false,
     "grade_id": "cell-7b2e074737588c42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "predict(lr_fit, new_data = OJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a1afd6eaff2e2f71bf12b09bb8b83dd",
     "grade": false,
     "grade_id": "cell-3dc8381171f81169",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The result is a tibble with a single column `.pred_class` which will be a factor variable of the same labels as the original training data set.\n",
    "\n",
    "We can also get back probability predictions, by specifying `type = \"prob\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1610f42bebb5d5caf63d991fdcbe57d3",
     "grade": false,
     "grade_id": "cell-9e6f6dc6988df569",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "predict(lr_fit, new_data = OJ, type = \"prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f724c3a169f858d62b96f43dec537f63",
     "grade": false,
     "grade_id": "cell-cc86a7fd45f79655",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can describe a `confusion matrix` that would help us understand how well the predictive model is preforming by given a table of predicted values against the true value\n",
    "\n",
    "`augment()` function helps add the predictions to the `data.frame` and then use that to look at model performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbe753fc0e5dd0f5382eeacdf62fcd2f",
     "grade": false,
     "grade_id": "cell-69d60cd022c6c6bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "augment(lr_fit, new_data = OJ) %>%\n",
    "  conf_mat(truth = Purchase, estimate = .pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "169db7e9efcf0f5df32ea0527018d7cd",
     "grade": false,
     "grade_id": "cell-7b1208536f105fc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " We can represent this as a `heatmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "845feb1e67b07e98792af97952268553",
     "grade": false,
     "grade_id": "cell-9207e5b34993407b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "augment(lr_fit, new_data = OJ) %>%\n",
    "  conf_mat(truth = Purchase, estimate = .pred_class) %>%\n",
    "  autoplot(type = \"heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "523c7edace5af223518db0b1affcaca2",
     "grade": false,
     "grade_id": "cell-6f0c6afa7d5e0c04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A good performing model would ideally have high numbers along the diagonal (up-left to down-right) with small numbers on the off-diagonal. We see here that the model isn’t great, as it tends to predict `\"CH\"` as `\"MM\"` more often than it should.\n",
    "\n",
    "We can also calculate various performance metrics. One of the most common metrics is accuracy, which is how often the model predicted correctly as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58c4483886130a4bc112e2078dcb56a9",
     "grade": false,
     "grade_id": "cell-c03344365627e23f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "augment(lr_fit, new_data = OJ) %>%\n",
    "  accuracy(truth = Purchase, estimate = .pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca040f8e067a5242d4eee9ead79f910f",
     "grade": false,
     "grade_id": "cell-b1f3a488719fb0b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Fitting a model and evaluating the model on the same data would give much information abou the model's performance.\n",
    "\n",
    "Let us instead split up the data, train it on some of it and then evaluate it on the other part of the data. Since we are working with some data that has a time component,lets train the data over a before a specific week and test it over the set of other weeks.\n",
    "\n",
    "This would more closely match how such a model would be used in real life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(WeekofPurchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1addaadad341d8625d46546a31fe5ec",
     "grade": false,
     "grade_id": "cell-e73167bd5ffbd3af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "oj_train <- OJ %>%\n",
    "  filter(WeekofPurchase < 260)\n",
    "dim(oj_train)\n",
    "\n",
    "oj_test <- OJ %>%\n",
    "  filter(WeekofPurchase >= 260)\n",
    "dim(oj_test)\n",
    "\n",
    "dim(OJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e28d958cfe744e680088687691da0a5",
     "grade": false,
     "grade_id": "cell-fde5f0f8e7eca7ee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Build an lr model that fits Purchase as response with other numeric variables\n",
    "# Predictors: PriceCH, PriceMM, DiscCH, DiscMM, PctDiscMM, PctDiscCH\n",
    "# Modeled over the training data set created above\n",
    "lr.fit = function(){\n",
    "    # your code here\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f85f855d60d9edafdd594c365ff993c",
     "grade": true,
     "grade_id": "cell-06859e488695c083",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "summary = lr.fit() %>% pluck('fit') %>% summary()\n",
    "coeff = coef(summary)\n",
    "\n",
    "stopifnot(round(coeff[1],2) == 1.47) #Intercept test case\n",
    "stopifnot(round(coeff[2],2) == 2.99) #PriceCH test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3f5ba8455a5ac50f1f998a6ae594cdf",
     "grade": true,
     "grade_id": "cell-3e3ced588f8559c9",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "628a613c36faf1ec5712ad12f2d3048e",
     "grade": false,
     "grade_id": "cell-f849d909e40977a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Return a confusion matrix and accuracy of the model lr.fit \n",
    "# the matrix has to be defined over the test data set \n",
    "confusion_matrix = function(){\n",
    "    # your code here\n",
    "    \n",
    "}\n",
    "\n",
    "accuracy.fit = function(){\n",
    "    # your code here\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9aec14babd2dead087bae5ad4945d04",
     "grade": true,
     "grade_id": "cell-29e6fd439853e584",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix()\n",
    "\n",
    "\n",
    "accuracy = accuracy.fit()\n",
    "stopifnot(round(accuracy[3],2) == 0.70) #Accuracy test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26e4729a0b36bfc054f12a5a18b792ec",
     "grade": true,
     "grade_id": "cell-e158590cce2be0ba",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4661267bfbbebacca242ff57e7682b8c",
     "grade": false,
     "grade_id": "cell-d46e87b57ba123be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Linear Discriminant Analysis\n",
    "\n",
    "We will use the `discrim_linear()` function to create a LDA specification. We are gonna use two predictors (`PriceCH` & `PriceMM`) for easy comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56433e57fdd92aa8d11689a92e720264",
     "grade": false,
     "grade_id": "cell-b5bba7cc3522abfb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lda_spec <- discrim_linear() %>%\n",
    "  set_mode(\"classification\") %>%\n",
    "  set_engine(\"MASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7237602a9991f189639d5daae9479372",
     "grade": false,
     "grade_id": "cell-b40348da1d6e01ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lda_fit = lda_spec %>%\n",
    "  fit(Purchase ~ PriceCH + PriceMM, data = oj_train)\n",
    "\n",
    "lda_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1753687a2cc4fcdf7153390b5040810d",
     "grade": false,
     "grade_id": "cell-7aac4f66c75535db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "predict(lda_fit, new_data = oj_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b42277d3baa2276f00d078fde2d3ce2e",
     "grade": false,
     "grade_id": "cell-9eef458bb7353ac6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "augment(lda_fit, new_data = oj_test) %>%\n",
    "  conf_mat(truth = Purchase, estimate = .pred_class)\n",
    "\n",
    "#accuracy \n",
    "augment(lda_fit, new_data = oj_test) %>%\n",
    "      accuracy(truth = Purchase, estimate = .pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72619dd1ff711eef5f9ac9a204b662bb",
     "grade": false,
     "grade_id": "cell-26b07540d8926c2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Lets compare this to `lr()` fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9a97a4de08897c77bf284d2c5546197",
     "grade": false,
     "grade_id": "cell-a818b5aa8c6d519b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lda_fit_2 = lda_spec %>%\n",
    "  fit(Purchase ~ PriceCH + PriceMM + DiscCH + DiscMM + PctDiscMM + PctDiscCH,\n",
    "      data = oj_train)\n",
    "\n",
    "#accuracy\n",
    "augment(lda_fit_2, new_data = oj_test) %>%\n",
    "      accuracy(truth = Purchase, estimate = .pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6b88339f40e067e2b94eea63658020f",
     "grade": false,
     "grade_id": "cell-eccae61c4b55610f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Quadratic Discriminant Analysis\n",
    "\n",
    "We can fit a `QDA` model by using the `discrim_quad()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d50e2183c73bb543eb535aa4b1289f70",
     "grade": false,
     "grade_id": "cell-d6c183b300f5c464",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "qda_spec = discrim_quad() %>%\n",
    "  set_mode(\"classification\") %>%\n",
    "  set_engine(\"MASS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1efaa16a4359ea5718871c644ad4a91b",
     "grade": false,
     "grade_id": "cell-d62fcc6afe72b8d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "`qda_spec` has a similar usage as `lda_spec`. so, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28c852bf5fc599bb3e074a01aa2e9cec",
     "grade": false,
     "grade_id": "cell-e541e2641dc2b9f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "qda_fit = qda_spec %>% fit(Purchase ~ PriceCH + PriceMM, \n",
    "                           data = oj_train)\n",
    "qda_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "142b9bf6c85a3f6266c7de56a5d69a0a",
     "grade": false,
     "grade_id": "cell-d44df489170715a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "augment(qda_fit, new_data = oj_test) %>%\n",
    "  conf_mat(truth = Purchase, estimate = .pred_class) \n",
    "\n",
    "#accuracy\n",
    "augment(qda_fit, new_data = oj_test) %>%\n",
    "  accuracy(truth = Purchase, estimate = .pred_class) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c8b63a2d08c21956a3c114e51f0f781",
     "grade": false,
     "grade_id": "cell-154f90adae8fe5f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see that, `QDA` performs better compared to `LDA` using two predictors\n",
    "\n",
    "Now lets compare all the three fits with 6 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "576fcec4d61f7e7a9c13f02d7e568292",
     "grade": false,
     "grade_id": "cell-2c9956278e266e61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "qda_fit_2 = qda_spec %>%\n",
    "  fit(Purchase ~ PriceCH + PriceMM + DiscCH + DiscMM + PctDiscMM + PctDiscCH,\n",
    "      data = oj_train)\n",
    "\n",
    "#accuracy\n",
    "augment(qda_fit_2, new_data = oj_test) %>%\n",
    "      accuracy(truth = Purchase, estimate = .pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e23cc532d4aef2b77e365365b2fe4b73",
     "grade": false,
     "grade_id": "cell-8d7488f900dacd01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "get_accuracy = function(fit){\n",
    "    accuracy = augment(fit, new_data = oj_test) %>% \n",
    "      accuracy(truth = Purchase, estimate = .pred_class)\n",
    "    accuracy[3]\n",
    "}\n",
    "accuracy_matrix = matrix(c( get_accuracy(lr.fit())\n",
    "                           , get_accuracy(lda_fit_2)\n",
    "                           , get_accuracy(qda_fit_2))\n",
    "                           , nrow = 1, ncol = 3, byrow=FALSE)\n",
    "colnames(accuracy_matrix) = c(\"LR\", \"LDA\", \"QDA\")\n",
    "accuracy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "810e8e6ae8119982d0f2110a579c0e74",
     "grade": false,
     "grade_id": "cell-4676719415fc5c20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "we can see that the `QDA` works better for this data where as `LDA` and `LR` work similary for this data set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
