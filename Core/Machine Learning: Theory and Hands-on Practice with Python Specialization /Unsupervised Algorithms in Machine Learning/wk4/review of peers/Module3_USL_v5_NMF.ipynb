{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f326db8bed1279d8025ccf538456390",
     "grade": false,
     "grade_id": "cell-3c31370d71a476a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment itemâ€”not the total point value in the nbgrader notebook.<br>\n",
    "When calculating the final score shown to learners, the programming assignment takes the percentage of earned points vs. the total points provided by nbgrader and returns a score matching the equivalent percentage of the point value for the programming assignment. <br>\n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if your change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b2ef6efc5deee97a474a1b0d8b07bca",
     "grade": false,
     "grade_id": "cell-fb09c135cd86a7c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Validate Button\n",
    "Please note that this assignment uses nbgrader to facilitate grading. You will see a **validate button** at the top of your Jupyter notebook. If you hit this button, it will run tests cases for the lab that aren't hidden. It is good to use the validate button before submitting the lab. Do know that the labs in the course contain hidden test cases. The validate button will not let you know whether these test cases pass. After submitting your lab, you can see more information about these hidden test cases in the Grader Output. <br>\n",
    "***Cells with longer execution times will cause the validate button to time out and freeze. Please know that if you run into Validate time-outs, it will not affect the final submission grading.*** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32e45eb6bcc8c7d1db2d846fc120d426",
     "grade": false,
     "grade_id": "cell-e212d9fd41f03b18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Building Recommender Systems for Movie Rating Prediction\n",
    "\n",
    "In this assignment, we will build a recommender systems that predict movie ratings. [MovieLense](https://grouplens.org/datasets/movielens/) has currently 25 million user-movie ratings.  Since the entire data is too big, we use  a 1 million ratings subset [MovieLens 1M](https://www.kaggle.com/odedgolden/movielens-1m-dataset), and we reformatted the data to make it more convenient to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "069f66d81507ea520c1fe5098352b437",
     "grade": false,
     "grade_id": "cell-ea989c7a4eb25b70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.spatial.distance import jaccard, cosine \n",
    "from pytest import approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdeafa5886528c497f33ffde32d9b7bb",
     "grade": false,
     "grade_id": "cell-476e59a408937946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "MV_users = pd.read_csv('data/users.csv')\n",
    "MV_movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0ddf339d993a9dfb1046fa9c762eb28",
     "grade": false,
     "grade_id": "cell-9dea5c452642998d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uID gender  age  accupation    zip\n",
      "0    1      F    1          10  48067\n",
      "1    2      M   56          16  70072\n",
      "   mID      title  year  Doc  Com  Hor  Adv  Wes  Dra  Ani  ...  Chi  Cri  \\\n",
      "0    1  Toy Story  1995    0    1    0    0    0    0    1  ...    1    0   \n",
      "1    2    Jumanji  1995    0    0    0    1    0    0    0  ...    1    0   \n",
      "\n",
      "   Thr  Sci  Mys  Rom  Fil  Fan  Act  Mus  \n",
      "0    0    0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    1    0    0  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "    uID   mID  rating\n",
      "0   744  1210       5\n",
      "1  3040  1584       4\n",
      "    uID  mID  rating\n",
      "0  2233  440       4\n",
      "1  4274  587       5\n"
     ]
    }
   ],
   "source": [
    "print(data.users[:2])\n",
    "print(data.movies[:2])\n",
    "print(data.train[:2])\n",
    "print(data.test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58249f70f1dc6b13ee151e49b58c073b",
     "grade": false,
     "grade_id": "cell-ee6ea083a19e98e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Starter codes\n",
    "Now, we will be building a recommender system which has various techniques to predict ratings. \n",
    "The `class RecSys` has baseline prediction methods (such as predicting everything to 3 or to average rating of each user) and other utility functions. `class ContentBased` and `class Collaborative` inherit `class RecSys` and further add methods calculating item-item similarity matrix. You will be completing those functions using what we learned about content-based filtering and collaborative filtering.\n",
    "\n",
    "`RecSys`'s `rating_matrix` method converts the (user id, movie id, rating) triplet from the train data (train data's ratings are known) into a utility matrix for 6040 users and 3883 movies.    \n",
    "Here, we create the utility matrix as a dense matrix (numpy.array) format for convenience. But in a real world data where hundreds of millions of users and items may exist, we won't be able to create the utility matrix in a dense matrix format (For those who are curious why, try measuring the dense matrix self.Mr using .nbytes()). In that case, we may use sparse matrix operations as much as possible and distributed file systems and distributed computing will be needed. Fortunately, our data is small enough to fit in a laptop/pc memory. Also, we will use numpy and scipy.sparse, which allow significantly faster calculations than calculating on pandas.DataFrame object.    \n",
    "In the `rating_matrix` method, pay attention to the index mapping as user IDs and movie IDs are not the same as array index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.862365426778359\n"
     ]
    }
   ],
   "source": [
    "# Load the movie ratings data (as in the HW3-recommender-system) and use matrix factorization technique(s) \n",
    "# and predict the missing ratings from the test data. Measure the RMSE. You should use sklearn library.\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class NMFRecSys(RecSys):\n",
    "    def __init__(self, data, n_components=20):\n",
    "        super().__init__(data)\n",
    "        self.n_components = n_components\n",
    "        self.U = None\n",
    "        self.V = None\n",
    "\n",
    "    def fit(self):\n",
    "        # Create the ratings matrix\n",
    "        num_users = len(self.allusers)\n",
    "        num_movies = len(self.allmovies)\n",
    "        ratings_matrix = np.zeros((num_users, num_movies))\n",
    "\n",
    "        # Map movie IDs to matrix indices\n",
    "        movie_id_to_idx = {mID: idx for idx, mID in enumerate(self.allmovies)}\n",
    "\n",
    "        for uID, mID, rating in self.data.train[['uID', 'mID', 'rating']].values:\n",
    "            ratings_matrix[uID-1, movie_id_to_idx[mID]] = rating\n",
    "\n",
    "        # Apply NMF to decompose the rating matrix\n",
    "        nmf = NMF(n_components=self.n_components, random_state=42)\n",
    "        self.U = nmf.fit_transform(ratings_matrix)\n",
    "        self.V = nmf.components_\n",
    "\n",
    "    def predict(self):\n",
    "        # Reconstruct the ratings matrix by multiplying U and V\n",
    "        predicted_ratings = self.U.dot(self.V)\n",
    "\n",
    "        # Get the predicted ratings for the test dataset\n",
    "        predicted_test_ratings = []\n",
    "        # Map movie IDs to matrix indices\n",
    "        movie_id_to_idx = {mID: idx for idx, mID in enumerate(self.allmovies)}\n",
    "        for uID, mID, rating in self.data.test[['uID', 'mID', 'rating']].values:\n",
    "            predicted_test_ratings.append(predicted_ratings[uID-1, movie_id_to_idx[mID]])\n",
    "\n",
    "        return np.array(predicted_test_ratings)\n",
    "\n",
    "    def rmse(self, yp):\n",
    "        yp[np.isnan(yp)] = 3  # Impute NaN values with 3\n",
    "        yt = np.array(self.data.test.rating)\n",
    "        return np.sqrt(((yt - yp) ** 2).mean())\n",
    "\n",
    "\n",
    "# Create an instance of NMFRecSys\n",
    "nmf_rec_sys = NMFRecSys(data)\n",
    "\n",
    "# Fit the NMF model\n",
    "nmf_rec_sys.fit()\n",
    "\n",
    "# Predict ratings\n",
    "predicted_ratings = nmf_rec_sys.predict()\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = nmf_rec_sys.rmse(predicted_ratings)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: having an RMSE value of around 2.8 means that, on average, the predicted ratings from the recommendation system deviate from the actual ratings by approximately 2.8 units. \n",
    "\n",
    "There are several reasons why non-negative matrix factorization (NMF) may not perform as well as other methods such as baseline or similarity-based methods. Firstly,  NMF may not have enough model complexity to capture the underlying patterns in the data. The number of components (latent factors) used in NMF can significantly impact its performance. If the chosen number of components is too low, the model may struggle to represent the data accurately.Secondly, NMF is sensitive to the initialization of the factor matrices. Different initializations can lead to different solutions and affect the model's performance. \n",
    "To deal with this, we can increase model complexity by increasing the number of components (latent factors) used in NMF. This can allow the model to capture more intricate patterns in the data. We can also try different implementations and explore their hyperparameters, initialization methods, and optimization algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
