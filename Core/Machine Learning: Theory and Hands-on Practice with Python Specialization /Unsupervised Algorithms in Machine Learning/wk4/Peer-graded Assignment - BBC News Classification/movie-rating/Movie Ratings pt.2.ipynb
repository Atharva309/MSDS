{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "966dd465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a69516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('data/users.csv')\n",
    "movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fde1ff46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: \n",
      "   uID gender  age  accupation    zip\n",
      "0    1      F    1          10  48067\n",
      "1    2      M   56          16  70072\n",
      "2    3      M   25          15  55117\n",
      "3    4      M   45           7  02460\n",
      "4    5      M   25          20  55455\n",
      "\n",
      "Movies: \n",
      "   mID                        title  year  Doc  Com  Hor  Adv  Wes  Dra  Ani  \\\n",
      "0    1                    Toy Story  1995    0    1    0    0    0    0    1   \n",
      "1    2                      Jumanji  1995    0    0    0    1    0    0    0   \n",
      "2    3             Grumpier Old Men  1995    0    1    0    0    0    0    0   \n",
      "3    4            Waiting to Exhale  1995    0    1    0    0    0    1    0   \n",
      "4    5  Father of the Bride Part II  1995    0    1    0    0    0    0    0   \n",
      "\n",
      "   ...  Chi  Cri  Thr  Sci  Mys  Rom  Fil  Fan  Act  Mus  \n",
      "0  ...    1    0    0    0    0    0    0    0    0    0  \n",
      "1  ...    1    0    0    0    0    0    0    1    0    0  \n",
      "2  ...    0    0    0    0    0    1    0    0    0    0  \n",
      "3  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "4  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Train: \n",
      "    uID   mID  rating\n",
      "0   744  1210       5\n",
      "1  3040  1584       4\n",
      "2  1451  1293       5\n",
      "3  5455  3176       2\n",
      "4  2507  3074       5\n",
      "\n",
      "Test: \n",
      "    uID   mID  rating\n",
      "0  2233   440       4\n",
      "1  4274   587       5\n",
      "2  2498   454       3\n",
      "3  2868  2336       5\n",
      "4  1636  2686       5\n"
     ]
    }
   ],
   "source": [
    "print(f'Users: \\n{users.head()}\\n')\n",
    "print(f'Movies: \\n{movies.head()}\\n')\n",
    "print(f'Train: \\n{train.head()}\\n')\n",
    "print(f'Test: \\n{test.head()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e98cd7",
   "metadata": {},
   "source": [
    "Load ratings data and use matrix factorization techniques and predict the missing ratings from the test data. Measure the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d082ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "allusers = list(users['uID'])\n",
    "allmovies = list(movies['mID'])\n",
    "mid2idx = dict(zip(movies.mID,list(range(len(movies)))))\n",
    "uid2idx = dict(zip(users.uID,list(range(len(users)))))\n",
    "ind_movie = [mid2idx[x] for x in train.mID] \n",
    "ind_user = [uid2idx[x] for x in train.uID]\n",
    "rating_train = list(train.rating)\n",
    "Mr = np.array(coo_matrix((rating_train, (ind_user, ind_movie)), shape=(len(allusers), len(allmovies))).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af7e5adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [3, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72c86f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3883)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adbf6f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029852745794625237"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the sparsity\n",
    "len(Mr.nonzero()[0]) / float(Mr.shape[0] * Mr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80c4f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1692: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = NMF(n_components=20)     \n",
    "W = model.fit_transform(Mr)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c721c25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "281d795c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3883)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d987857",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_movie_test = [mid2idx[x] for x in test.mID] \n",
    "ind_user_test = [uid2idx[x] for x in test.uID]\n",
    "rating_test = list(test.rating)\n",
    "Mr_test = np.array(coo_matrix(\n",
    "    (rating_test, (ind_user_test, ind_movie_test)), \n",
    "    shape=(len(allusers), len(allmovies))).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c6e32ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad4de1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3883)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mr_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c096efcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012794052185362243"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Mr_test.nonzero()[0]) / float(Mr_test.shape[0] * Mr_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "105e78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mr_pred = H.T.dot(W.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df28be3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.78561924e+00, 5.35822187e-01, 1.59740139e-02, ...,\n",
       "        1.30735004e-02, 6.42771938e-03, 9.26652383e-02],\n",
       "       [1.26557355e+00, 3.72001854e-01, 1.34497823e-01, ...,\n",
       "        1.58572552e-02, 0.00000000e+00, 3.85520995e-02],\n",
       "       [6.85354227e-01, 1.45091941e-01, 2.53994011e-03, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [6.58618577e-01, 1.33013509e-02, 8.07949334e-04, ...,\n",
       "        1.29707703e-03, 0.00000000e+00, 8.92649818e-05],\n",
       "       [1.25687321e+00, 2.87928423e-01, 9.35396638e-02, ...,\n",
       "        4.93460949e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.34773976e+00, 9.75702074e-02, 5.90561503e-03, ...,\n",
       "        9.29470025e-02, 9.13006316e-02, 4.16696932e-01]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5b369da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(\n",
    "    Mr_pred[Mr_test.nonzero()].flatten(), \n",
    "    Mr_test[Mr_test.nonzero()].flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f7f4fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8624319319601716"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a162f",
   "metadata": {},
   "source": [
    "Discuss the results and why they did not work well compared to simple baseline or similarity-based methods we’ve done in Module 3. Can you suggest a way(s) to fix it?\n",
    "\n",
    "- The result rmse 2.86 did not look good, simple baseline is around 1.26 rmse per week3 assignment\n",
    "- NMF didn't take true movie and user features into account, but purely based on user-movie rating matrix\n",
    "- Also NMF default l2 loss does not work well for sparse matrix which has lots of 0\n",
    "- Tuning n_components may be helpful to improve the performance through gridsearchcv; And using Kl loss is good for data that has lots of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7594ac73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
