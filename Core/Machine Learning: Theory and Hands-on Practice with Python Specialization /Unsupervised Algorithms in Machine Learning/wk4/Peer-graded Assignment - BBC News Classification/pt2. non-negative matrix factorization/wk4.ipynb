{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419d2b8d",
   "metadata": {},
   "source": [
    "## 1. Load the movie ratings data (as in the HW3-recommender-system) and use matrix factorization technique(s) and predict the missing ratings from the test data. Measure the RMSE. You should use sklearn library. [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3b7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702089e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "MV_users = pd.read_csv('data/users.csv')\n",
    "MV_movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "from collections import namedtuple\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bffb0e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum user and movie IDs from the data\n",
    "max_user_id = data.train['uID'].max()\n",
    "max_movie_id = data.train['mID'].max()\n",
    "\n",
    "# Create user-item rating matrix\n",
    "ratings_matrix = np.zeros((max_user_id, max_movie_id))\n",
    "\n",
    "for index, row in data.train.iterrows():\n",
    "    user_id = row['uID']\n",
    "    movie_id = row['mID']\n",
    "    rating = row['rating']\n",
    "    ratings_matrix[user_id - 1, movie_id - 1] = rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e4a71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1692: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply Non-Negative Matrix Factorization (NMF)\n",
    "n_components = 10  # Number of latent factors\n",
    "model = NMF(n_components=n_components, init='random', random_state=0)\n",
    "W = model.fit_transform(ratings_matrix)\n",
    "H = model.components_\n",
    "\n",
    "# Predict missing ratings\n",
    "predicted_ratings = np.dot(W, H)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f3ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum user and movie IDs from the testing data\n",
    "max_test_user_id = data.test['uID'].max()\n",
    "max_test_movie_id = data.test['mID'].max()\n",
    "\n",
    "# Create the test_ratings_matrix with adjusted dimensions\n",
    "test_ratings_matrix = np.zeros((max_test_user_id, max_test_movie_id))\n",
    "\n",
    "for index, row in data.test.iterrows():\n",
    "    user_id = row['uID']\n",
    "    movie_id = row['mID']\n",
    "    test_ratings_matrix[user_id - 1, movie_id - 1] = row['rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679aa73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.91409307190423\n"
     ]
    }
   ],
   "source": [
    "test_mask = test_ratings_matrix > 0\n",
    "predicted_test_ratings = predicted_ratings[test_mask]\n",
    "actual_test_ratings = test_ratings_matrix[test_mask]\n",
    "\n",
    "rmse = sqrt(mean_squared_error(actual_test_ratings, predicted_test_ratings))\n",
    "print(f'RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "022402ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1692: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.91409307190423\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "# Load the data\n",
    "MV_users = pd.read_csv('data/users.csv')\n",
    "MV_movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "from collections import namedtuple\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)\n",
    "\n",
    "\n",
    "# Get the maximum user and movie IDs from the data\n",
    "max_user_id = data.train['uID'].max()\n",
    "max_movie_id = data.train['mID'].max()\n",
    "\n",
    "# Create user-item rating matrix\n",
    "ratings_matrix = np.zeros((max_user_id, max_movie_id))\n",
    "\n",
    "for index, row in data.train.iterrows():\n",
    "    user_id = row['uID']\n",
    "    movie_id = row['mID']\n",
    "    rating = row['rating']\n",
    "    ratings_matrix[user_id - 1, movie_id - 1] = rating\n",
    "\n",
    "    \n",
    "\n",
    "# Apply Non-Negative Matrix Factorization (NMF)\n",
    "n_components = 10  # Number of latent factors\n",
    "model = NMF(n_components=n_components, init='random', random_state=0)\n",
    "W = model.fit_transform(ratings_matrix)\n",
    "H = model.components_\n",
    "\n",
    "# Predict missing ratings\n",
    "predicted_ratings = np.dot(W, H)\n",
    "\n",
    "# Get the maximum user and movie IDs from the testing data\n",
    "max_test_user_id = data.test['uID'].max()\n",
    "max_test_movie_id = data.test['mID'].max()\n",
    "\n",
    "# Create the test_ratings_matrix with adjusted dimensions\n",
    "test_ratings_matrix = np.zeros((max_test_user_id, max_test_movie_id))\n",
    "\n",
    "for index, row in data.test.iterrows():\n",
    "    user_id = row['uID']\n",
    "    movie_id = row['mID']\n",
    "    test_ratings_matrix[user_id - 1, movie_id - 1] = row['rating']\n",
    "\n",
    "test_mask = test_ratings_matrix > 0\n",
    "predicted_test_ratings = predicted_ratings[test_mask]\n",
    "actual_test_ratings = test_ratings_matrix[test_mask]\n",
    "\n",
    "rmse = sqrt(mean_squared_error(actual_test_ratings, predicted_test_ratings))\n",
    "print(f'RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48eced",
   "metadata": {},
   "source": [
    "## 2. Discuss the results and why sklearn's non-negative matrix facorization library did not work well compared to simple baseline or similarity-based methods weâ€™ve done in Module 3. Can you suggest a way(s) to fix it? [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e6bcca",
   "metadata": {},
   "source": [
    "To discuss the results and understand why sklearn's Non-Negative Matrix Factorization (NMF) library might not have worked as well compared to simple baseline or similarity-based methods, let's break down some potential reasons:\n",
    "\n",
    "1. **Loss of Information**: NMF works by factorizing the original matrix into two matrices, which might not fully capture all the nuances of the data. This loss of information can lead to suboptimal performance, especially when dealing with sparse or noisy data.\n",
    "\n",
    "2. **Choice of Hyperparameters**: The choice of hyperparameters, such as the number of latent factors (`n_components` in your case), can significantly impact the performance of NMF. If the chosen number of latent factors is not appropriate, the model might fail to capture the underlying patterns in the data.\n",
    "\n",
    "3. **Initialization Sensitivity**: NMF is sensitive to the choice of initial values. Different initializations can lead to different factorized matrices and therefore varying results. In your code, you've used `'init'='random'`, which might not always yield the best results.\n",
    "\n",
    "4. **Scalability**: NMF might not scale well to large datasets due to its computational complexity. This could lead to longer training times and potentially less accurate results on larger datasets.\n",
    "\n",
    "5. **Non-Convex Optimization**: NMF involves non-convex optimization, meaning that there can be multiple local minima in the optimization landscape. This can result in the algorithm getting stuck in suboptimal solutions.\n",
    "\n",
    "6. **Complexity of the Problem**: The movie recommendation problem is inherently complex, and simple matrix factorization methods like NMF might not capture all the intricate relationships between users and movies as well as more advanced techniques.\n",
    "\n",
    "To improve the performance of NMF or address its limitations, you can consider the following strategies:\n",
    "\n",
    "1. **Tune Hyperparameters**: Experiment with different values of the `n_components` hyperparameter to find the optimal number of latent factors. This can be done through cross-validation on your training data.\n",
    "\n",
    "2. **Advanced Initialization**: Instead of random initialization, you can try using other initialization techniques like \"Nndsvd\" or \"nndsvda\" available in sklearn's NMF implementation. These methods are designed to provide better starting points for optimization.\n",
    "\n",
    "3. **Regularization**: Incorporate regularization terms into the NMF objective function. Regularization can help prevent overfitting and improve generalization to the test data.\n",
    "\n",
    "4. **Use Other Matrix Factorization Techniques**: Consider trying other matrix factorization methods, such as Singular Value Decomposition (SVD), which can capture more complex relationships in the data.\n",
    "\n",
    "5. **Ensemble Methods**: Combine NMF with other techniques, like collaborative filtering or content-based methods, in an ensemble approach. This can potentially mitigate the limitations of NMF by leveraging the strengths of different methods.\n",
    "\n",
    "6. **Advanced Collaborative Filtering**: Explore more advanced collaborative filtering techniques like matrix factorization with implicit feedback, which can handle the sparsity of the data more effectively.\n",
    "\n",
    "7. **Deep Learning**: Consider using deep learning techniques like autoencoders or neural collaborative filtering, which can capture intricate patterns in the data and might lead to better results.\n",
    "\n",
    "8. **Evaluation Metrics**: Besides RMSE, consider using other evaluation metrics such as precision, recall, and F1-score, which can provide a more comprehensive view of the recommendation system's performance.\n",
    "\n",
    "In conclusion, while sklearn's NMF library can be a useful tool for matrix factorization tasks, it might not work as well as simpler methods or more advanced techniques in certain scenarios. By carefully tuning hyperparameters, exploring initialization methods, and considering other matrix factorization approaches, you can potentially improve the performance of your recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233cf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
