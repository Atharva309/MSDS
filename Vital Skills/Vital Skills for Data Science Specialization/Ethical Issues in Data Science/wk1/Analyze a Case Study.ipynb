{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a case study from the ones provided with the ACM Code of Professional Ethics, at https://www.acm.org/code-of-ethics/case-studies.   Write and post (on the discussion board) an essay of 500-800 words that:\n",
    "\n",
    "- Briefly analyzes this case from the perspectives of each of the ethical frameworks we have studied: Kantianism/Deontology; Virtue Ethics; Utilitarianism.   For each, do you feel that framework suggests whether the situation is ethical or not?  Or do you feel it does not lead to a conclusive determination?   Whichever you feel (ethical / inconclusive / not-ethical) please state briefly what you feel that framework leads to that conclusion.\n",
    "\n",
    "- From what you have seen so far, which ethical frameworks appeal to you most, and least, and why?   \n",
    "\n",
    "Please note that there are rarely right and wrong answers to questions framed for short essay responses in this course.   Rather, the goal is to think issues through from a variety of perspectives. \n",
    "\n",
    "Please note also: if you decide to upgrade your enrollment in this course to receive credit in CU’ Boulder’s MS-DS program, you will lose access to the discussion posts you submitted in the non-credit version. Since you will need your old discussion posts in order to complete the final assignment, we suggest that you save your discussion responses in a separate document so that you will still have access to them should you decide to upgrade your enrollment to the for-credit version of the course. Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ethics.acm.org/code-of-ethics/using-the-code/case-automated-active-response-weaponry/\n",
    "\n",
    "Case: Automated Active Response Weaponry\n",
    "\n",
    "Using the Code: Automated Active Response Weaponry\n",
    "\n",
    "Q Industries is an international defense contractor that specializes in autonomous vehicles. Q’s early work focused on passive systems, such as bomb-defusing robots and crowd-monitoring drones. As an early pioneer in this area, Q established itself as a vendor of choice for both military and law enforcement applications. Q’s products have been deployed in a variety of settings, including conflict zones and non-violent protests.\n",
    "\n",
    "In recent years, Q has suffered a number of losses, as protestors and other individuals have physically attacked the vehicles with rocks, guns, and other weapons. To reduce this problem, Q has begun to experiment with automated active responses. Q’s first approach was to employ facial recognition algorithms to record those present and to detect individuals who may pose a threat. This approach was shortly followed by automated non-lethal responses, such as tear gas, pepper spray, or acoustic weapons, to incapacitate threatening individuals.\n",
    "\n",
    "Q has recently been approached—in secret meetings—by multiple governments to expand this response to include lethal responses of varying scales. These capabilities range from targeted shooting of known individuals to releasing small-scale explosives. When Q leadership agreed to pursue these capabilities, several of Q’s original engineers resigned in protest. Some of these engineers had previously expressed concern that the non-lethal responses had inadequate protections against tampering, such as replacing tear gas with a lethal poison. Knowing that these individuals were planning to speak out publicly, Q sued them for violating the terms of their confidentiality employment agreement.\n",
    "\n",
    "Analysis\n",
    "\n",
    "Principle 1.2 states that systems designed with the intention of causing harm must be ethically justified and must minimize unintended harm. Q’s evolving work shows a gradual process toward violating this principle. Q’s first automated response employed machine learning in a way that could be used to suppress free speech and association, which are fundamental human rights (Principle 1.1). By failing to account for this risk, Q failed to adhere to Principle 2.5’s mandate of extraordinary care regarding risks in machine learning systems. Furthermore, these tools could be used by governments that do not respect the values expressed in Principle 1.4, allowing discrimination and other abuses. This technology also failed to respect the privacy of other individuals who may be innocent bystanders (Principle 1.6). Additionally, the harm induced by the non-lethal weapons was not minimized, as these weapons would subject innocent individuals to pain or death without due process. Thus, the harm made possible here is not ethically justified and violates Principle 1.2.\n",
    "\n",
    "The engineers who resigned and decided to speak out would be justified in doing so, based on Principles 1.2, 1.7, and 2.7. The harm that Q’s systems made possible violated several aspects of the ethical obligations of the Code. Thus, the engineers were right to foster public awareness of these risks, and breaking their confidentiality agreements would be ethically justified. At the same time, Q’s lawsuit is justified and the engineers must accept the consequences for breaking these agreements, per Principle 2.3.\n",
    "\n",
    "Overall, Q’s leadership failed to respect the Code’s overarching emphasis on the public good. The Preamble introduces this emphasis by stating that public good is the paramount consideration. Principle 3.1 reiterates this point, declaring that people should always be the central concern. Q’s leadership failed to adhere to this key tenet that underlies the other principles of the Code.\n",
    "\n",
    "These cases studies are designed for educational purposes to illustrate how to apply the Code to analyze complex situations. All names, businesses, places, events, and incidents are fictitious and are not intended to refer to actual entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
