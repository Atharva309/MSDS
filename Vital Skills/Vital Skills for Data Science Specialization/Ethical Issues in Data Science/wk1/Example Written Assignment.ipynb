{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7484be7-827c-44d1-80e5-9921f1d3275b",
   "metadata": {},
   "source": [
    "  Example Paper\n",
    "\n",
    "Durbhakula, Shravani (2022, March 27) \"IBM dumping Watson Health is an opportunity to reevaluate artificial intelligence\" MedCity News https://medcitynews.com/2022/03/ibm-dumping-watson-health-is-an-opportunity-to-reevaluate-artificial-intelligence/ \n",
    "\n",
    "  \n",
    "\n",
    "Article Summary \n",
    "\n",
    "  \n",
    "\n",
    "This article describes the 1970s and 1990s as periods when the reality of artificial intelligence fell far short of the optimistic forecasts and asks whether the same thing is going to happen again as we try to apply AI to topics like healthcare. The author focuses on the data on which artificial intelligence algorithms are built, the electronic health record, or EHR, which is in poor shape. According to the article, electronic health records do not collect and report patient information with high enough quality. The EHR software used by doctors and nurses can be hard to use and often doesn’t align well with the way the healthcare practitioners actual work. These factors contribute to errors in the data. On top of that, there’s no systematic reporting and thus no real visibility into the number of medical errors in the EHRs. Machine learning algorithms which rely on EHR data are less effective because of the errors. The MD Anderson Cancer Center partnered with IBM to use their Watson AI in its efforts to eradicate cancer. This project failed and IBM later decided to sell its Watson division. \n",
    "\n",
    "  \n",
    "\n",
    "Ethical Issue \n",
    "\n",
    "  \n",
    "\n",
    "As the healthcare industry races to adopt technology, specifically AI, a key ethical question is whether they’re moving too fast and relying too heavily on algorithms that may be vulnerable to poor training data. There’s plenty of coverage in the media of both successes and failures of AI systems in healthcare settings. Some applications appear to be doing very well, helping to provide earlier diagnosis of some diseases than human doctors, for example. But there have also been cases of things like algorithmic bias due to some groups being underrepresented in the training data. Compounding the problem is the fact that many machine learning systems are opaque; it’s not possible to follow its \"reasoning\" for a given result. So, neither the doctors nor the patients have clarity whether there might be errors due to bad underlying data. One reasonable point of view is that AI has shown its value in many medical situations, and as the quality of EHR data improves, the AI systems will only get better. An equally valid perspective is that bad underlying data could lead to hidden problems that are hard to predict or even detect, and when human lives are at stake, the risk is too high. \n",
    "\n",
    "  \n",
    "\n",
    "Ethical Analysis\n",
    "\n",
    "  \n",
    "\n",
    " To evaluate this ethical question, we start with the fact that medicine has always been an inexact science, full of trade offs and judgment calls. Most medicines and medical procedures have risks and side effects; the task is to balance them for the best projected outcome. It is natural, then, that many ethics questions in medicine are evaluated using a utilitarian framework. There have been enough positive cases using AI that the alternative of halting its adoption would not be the ethical choice. AI systems, at least in some situations, has improved healthcare overall. One example is in the field of radiology where AI acts as another \"pair of eyes\" and helps to reduce the number of false negative diagnoses. Used in this limited fashion, there is clear benefit and very little cost. However, this does not mean that the current pace of AI adoption is the right alternative either. There are both real downsides, like biased algorithms, and less concrete risks, such as the possible erosion of trust between patients and doctors. The cost of these is hard to quantify but it must be weighed against the benefits. This suggests that minimizing these downsides needs to be part of the adoption of AI in healthcare to be the best alternative under utilitarianism. An ethical approach needs to incorporate an appropriate level of quality assurance, clinical trials, and improvements to the underlying training data. Transparency and reporting will be needed to properly assess the effectiveness of these measures. As long as hospitals and doctors make the effort to consider and minimize these costs, the adoption of AI promises to promote the general welfare, and is therefore an ethical choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d7252-e191-4ec9-bb4e-ad355801b61b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
