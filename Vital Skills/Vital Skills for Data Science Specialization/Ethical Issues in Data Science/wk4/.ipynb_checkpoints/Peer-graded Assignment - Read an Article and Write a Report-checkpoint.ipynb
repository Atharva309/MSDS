{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84afca59",
   "metadata": {},
   "source": [
    "Find a recent media article that is relevant to the topic of algorithmic bias and is of interest to you. (Note: You may not use one of the assigned course readings for your report, although you may use one of the optional readings). Then write a report of 500-800 words that includes:\n",
    "\n",
    "    The reference information for the article (title, author, where and when published, link if online)\n",
    "\n",
    "    A summary of the content of the article\n",
    "\n",
    "    The issue(s) in data ethics that this article is relevant to\n",
    "\n",
    "    Your assessment of whether the issues discussed in the article are being handled and resolved properly, and what additional steps you feel should be considered.  Please refer to at least one ethical framework in making this assessment\n",
    "\n",
    "Paste your report into the provided textbox for submission.\n",
    "\n",
    "You will then review the reports of three of your peers and three peers will review your report. You will not receive a grade until reviews are complete.\n",
    "\n",
    "Your report should be in your own words. If you use any material that is directly copied from another author, you must place this material in quotation marks and properly cite it. Failure to do so constitutes plagiarism, which is grounds to fail not only the plagiarized assignment, but the course.\n",
    "\n",
    "Note: The peer grading is blind (that is, your name is not seen by others) so long as you do not put your name or other personally identifying information in the assignment title\n",
    "or the essay itself. Please do not put any self-identifying information in the essay title or the essay itself.\n",
    "\n",
    "GRADING RUBRIC:\n",
    "\n",
    "Does your peer clearly describe the topic of the article, in their own words? (150-300 words)\n",
    "\n",
    "◻Your peer correctly identifies the main topic of the article and clearly describes it in their own words. Their description of the topic is at least 150 words.(5 points)\n",
    "\n",
    "◻Your peer correctly identifies the main topic of the article in their own words. However, their description of the topic is either unclear or else is less than 150 words.(3 points).\n",
    "\n",
    "◻Your peer does not describe the topic of the article.(0 points)\n",
    "\n",
    "Does your peer clearly identify one or more ethically relevant issues raised by the article? (In order to be an “ethically relevant” issue, it must be possible for there to be two or more reasonable[1]but opposing viewpoints about whether the issue is being handled ethically or unethically). (150-300 words)\n",
    "\n",
    "◻Your peer clearly identifies at least one ethically relevant issue. In addition, they explain why there might be reasonable but opposing viewpoints about whether the issue is being handled ethically or unethically. Their description of the ethical issue is at least 150 words.(5 points)\n",
    "\n",
    "◻Your peer identifies at least one ethically relevant issue brought up by the article, but either 1) their description is too short, or 2) they do not satisfactorily explain why there might be reasonable but opposing viewpoints about whether the issue is being handled ethically or unethically.(3 points).\n",
    "\n",
    "◻Your peer either does not identify an issue brought up by the article, or the issue that they identify is not ethically relevant.(0 points)\n",
    "\n",
    "Does your peer take a stance on whether the relevant issue is being handled ethically or unethically, and do they defend their stance by correctly applying at least one of the three ethical frameworks discussed in class? (Note, for guidelines on what constitutes a “correct application” of an ethical framework, see the reading titled “Applying an Ethical Framework”) (200-400 words)\n",
    "\n",
    "◻Yes, completely. Moreover, this portion of their response is at least 200 words(5 points)\n",
    "\n",
    "◻Your peer takes a clear stance on whether the relevant issue is being handled ethically or unethically, and mentions at least one ethical framework discussed in class, but either 1) their analysis is too short, or 2) the way that they apply the ethical framework to the issue they are discussing demonstrates a misunderstanding of the ethical framework. (For more on this, see the “Applying an Ethical Framework” reading).(3 points)\n",
    "\n",
    "◻Your peer either does not take a stance on whether the relevant issue is being handled ethically or unethically, or else does not mention any of the three ethical frameworks discussed in class.(0 points)\n",
    "\n",
    "\n",
    "[1]To say that a viewpoint is “reasonable” is to say that it is the kind of view that someone who was thinking critically about ethics might actually hold for justifiable reasons. Consideringreasonabledifferences of ethical opinion helps to avoid what is known as a straw man fallacy:this happens when we characterize one or the other viewpoint as wrong based on the weakest arguments for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c66b744",
   "metadata": {},
   "source": [
    "https://theweek.com/briefing/1023338/algorithm-ai-discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f700ba",
   "metadata": {},
   "source": [
    "How content creators cope with discriminatory algorithms\n",
    "'AI has embedded our cultural biases and threatens to perpetuate discriminatory human behavior'\n",
    "\n",
    "The threat of bias in the latest wave of generative artificial intelligence may be in the spotlight lately, but social media algorithms already have discrimination problems. Some creators from marginalized communities have expressed frustration with how the algorithms appeared biased against them, robbing them of critical engagement.\n",
    "How do social media algorithms discriminate against some creators?\n",
    "\n",
    "While content that doesn't violate any explicit terms can't be outright banned, social media companies still have ways of suppressing the work of some creators. Shadow-bans are \"a form of online censorship where you're still allowed to speak, but hardly anyone gets to hear you,\" The Washington Post explained. Their content might not be removed, but some creators notice that engagement with their posts plummets outside of their immediate friends. \"Even more maddening, no one tells you it's happening,\" the Post added.\n",
    "\n",
    "Content creators have long decried the lack of transparency with shadow-bans. Late last year, the practice made headlines when Twitter owner Elon Musk released the Twitter Files, internal company documents intended to show how \"shadow-banning was being used to suppress conservative views,\" the Post said. \n",
    "\n",
    "Shadow-banning is a form of algorithmic bias that disproportionately affects specific demographics because the \"unconscious biases of the developers are embedded in the systems they create,\" Annie Brown wrote for Forbes. Additionally, \"algorithms are trained by data gathered from human history, a history replete with violence, inequity, bias and cruelty,\" Brown posited. Shadow-bans are \"just one symptom of the inherent bias, racism and marginalization algorithms have detected and AI has co-opted,\" Brown opined. \"Seen this way, AI, under the guise of observation and platform moderation, has embedded our cultural biases and threatens to perpetuate discriminatory human behavior.\"\n",
    "Who has accused social media companies of algorithmic bias? \n",
    "\n",
    "Black creators have been speaking out about their content being suppressed since TikTok was accused of suppressing the content of Black creators during the George Floyd protests in 2020. The company later released a statement apologizing for a \"technical glitch\" that made it temporarily appear that \"posts uploaded using #BlackLivesMatter and #GeorgeFloyd would receive 0 views.\" Some creators alleged that their engagement still went down after posting content with those hashtags.  \n",
    "\n",
    "The following year, creators pointed out that terms like \"Black Lives Matter'' and \"Black people\" were flagged as inappropriate by the automated moderation system. In contrast, words like \"white supremacy\" or \"white success\" did not trigger a warning. Black dancers and choreographers also alleged that TikTok's recommendation algorithm prioritized white creators who copied their dances without giving them credit. This eventually led them to have a content strike on the platform that year. \n",
    "\n",
    "LGBTQ+ content creators have also raised concerns about their posts being taken down with little to no explanation, a practice labeled as \"the digital closet\"  by researcher and author Alexander Monea in his book of the same name. For his book about the overpolicing of LGBTQ-centered online spaces, Monea spent two years looking through data and collecting anecdotes from LGBTQ+ social media users who reported \"being censored, silenced or demonetized,\" ABC News explained. \n",
    "\n",
    "\"Once the internet is largely controlled by a very few companies that all use an advertising model to drive their revenue, what you get is an overpoliced sort of internet space,\" Monea told ABC's \"Perspective\" podcast.\n",
    "\n",
    "When Tumblr adopted an adult content ban in 2018, reports that the ban disproportionately affected LGBTQ+ users led to an investigation by New York City's Commission on Human Rights. In an interview, Monea said the \"automated content moderation algorithms that Tumblr implemented to help institute its new ban\" was \"comically inept but with tragic consequences.\" Many LGBTQ+ users lost all of their content \"with no redress and no way to recover their lost content or user base,\" Monea added. \n",
    "\n",
    "In 2022, Tumblr reached a settlement with New York City's Commission on Human Rights after an investigation was launched into the allegations of discrimination against LGBTQ+ users. The settlement required the platform to \"revise its user appeals process and train its human moderators on diversity and inclusion issues, as well as review thousands of old cases and hire an expert to look for potential bias in its moderation algorithms,\" The Verge summarized. \n",
    "How do creators cope with algorithmic bias? \n",
    "\n",
    "To avoid the looming threat of shadow-banning, some content creators have taken to using workarounds \"such as not using certain images, keywords or hashtags or by using a coded language known as algospeak,\" the Post explained. \n",
    "\n",
    "\"There's a line we have to toe; it's an unending battle of saying something and trying to get the message across without directly saying it,\" TikTok creator Sean Szolek-VanValkenburgh told the Post. \"It disproportionately affects the LGBTQIA community and the BIPOC community because we're the people creating that verbiage and coming up with the colloquiums.\"\n",
    "\n",
    "Some creators have attempted to fight against social media companies accused of discriminatory moderation with lawsuits. However, \"bias allegations against social media platforms have rarely succeeded in court,\" The Verge noted. YouTube won two lawsuits from LGBTQ+ and Black video creators who alleged algorithmic discrimination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd1702",
   "metadata": {},
   "source": [
    "Theara Coleman\n",
    "\n",
    "May 16, 2023\n",
    "\n",
    "How content creators cope with discriminatory algorithms\n",
    "\n",
    "https://theweek.com/briefing/1023338/algorithm-ai-discrimination\n",
    "\n",
    "theweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1587ce",
   "metadata": {},
   "source": [
    "Theara Coleman\n",
    "May 16, 2023\n",
    "How content creators cope with discriminatory algorithms\n",
    "https://theweek.com/briefing/1023338/algorithm-ai-discrimination\n",
    "theweek\n",
    "\n",
    "\n",
    "Summary:\n",
    "The article discusses the issue of algorithmic bias and discrimination faced by content creators on social media platforms. It highlights the practice of shadow-banning, where creators' content is suppressed, leading to a significant decline in engagement. The unconscious biases of developers and the training of algorithms on historical data contribute to these discriminatory outcomes. The article mentions cases where social media companies have been accused of algorithmic bias against marginalized communities, such as Black creators and LGBTQ+ content creators. Some creators have resorted to workarounds and coded language to navigate the biased algorithms. Legal action against social media platforms for discriminatory moderation has had limited success.\n",
    "\n",
    "Issues in Data Ethics:\n",
    "\n",
    "- Algorithmic Bias: The article raises concerns about the inherent biases present in algorithms due to the historical data they are trained on. These biases can lead to discriminatory outcomes, affecting specific demographics and perpetuating existing inequalities.\n",
    "\n",
    "- Lack of Transparency: The lack of transparency in how social media algorithms operate, including shadow-banning, raises ethical concerns. Content creators have expressed frustration over the opacity surrounding algorithmic decisions, as they are often unaware of the reasons behind their reduced visibility or engagement.\n",
    "\n",
    "Assessment of Handling and Resolution:\n",
    "The issues discussed in the article highlight the ongoing challenges of algorithmic bias and discrimination faced by content creators. While some social media platforms have acknowledged and addressed specific instances of bias, there is still significant room for improvement.\n",
    "\n",
    "From an ethical standpoint, it is crucial for social media companies to adopt a more transparent approach to algorithmic decision-making. This can include providing clear guidelines and explanations for content moderation actions, as well as offering avenues for appeal and redressal when unjustified biases are identified.\n",
    "\n",
    "One ethical framework that can be applied to assess the handling of these issues is the principles of fairness and justice. Social media platforms should ensure that their algorithms are designed and continuously monitored to minimize biases and ensure equitable treatment of all creators. This can be achieved through diverse development teams, algorithmic auditing, and incorporating feedback mechanisms from affected communities.\n",
    "\n",
    "In adition, platforms should proactively engage with marginalized communities, seeking their input and perspectives when developing and refining algorithms. Collaborative efforts, such as partnerships with external organizations or establishing advisory boards, can help address bias and discrimination concerns more effectively.\n",
    "\n",
    "Also, ongoing research and innovation in algorithmic fairness are essential. Social media companies should invest in developing and deploying algorithms that prioritize fairness and inclusivity, and regularly evaluate their impact to identify and rectify biases. fostering an open dialogue with content creators and communities affected by algorithmic bias can aid in building trust and improving accountability. By actively addressing concerns and implementing feedback, social media platforms can work towards creating a more inclusive and fair digital landscape for all users.\n",
    "\n",
    "In summary, addressing algorithmic bias requires a multi-faceted approach that combines transparency, inclusivity, and continuous improvement. By prioritizing fairness and justice, social media platforms can create an environment that empowers content creators from all backgrounds and fosters a more equitable online ecosystem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19454ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
