{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d6122f",
   "metadata": {},
   "source": [
    "# As artificial intelligence goes multimodal, medical applications multiply\n",
    "https://www.science.org/doi/10.1126/science.adk6139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a72bb1",
   "metadata": {},
   "source": [
    "Deep learning models have revolutionized medical image interpretation, allowing machines to see and analyze images such as X-rays, CT scans, MRIs, and pathology slides more accurately than humans. These \"machine eyes\" can reveal hidden information in medical images, offering insights into various aspects of human physiology and disease risk, from blood pressure to Alzheimer's disease. The true potential of artificial intelligence in medicine lies in its ability to move beyond image analysis and become multimodal.\n",
    "\n",
    "Multimodal AI combines text, audio, speech, and images, setting the stage for a broader range of applications in healthcare. To achieve multimodality, AI models require self-supervised and unsupervised learning, freeing them from the need for exhaustive data annotation. Multimodal AI can handle complex healthcare data, including anatomy, biomarkers, genomics, microbiomics, and more, providing a holistic view of an individual's health.\n",
    "\n",
    "This technology enables virtual health assistants to offer personalized guidance for preventing or managing chronic conditions. For instance, someone with high blood pressure and diabetes could receive continuous feedback based on various data sources, including physical activity, sleep patterns, and medical records. Remote monitoring becomes a reality, akin to a \"hospital-at-home\" with real-time vital sign monitoring and early warning systems.\n",
    "\n",
    "Multimodal AI also has potential in pandemic surveillance, offering individualized, real-time risk assessment by analyzing geolocation data, wearable sensor data, symptoms, vaccination status, and more.\n",
    "\n",
    "Despite the promise of multimodal AI, challenges remain. Overconfidence in AI responses, biases, data privacy concerns, model performance degradation, regulatory hurdles, and resistance to change in medical practice pose significant barriers.\n",
    "\n",
    "The convergence of immense computing power and self-supervised learning on vast datasets has paved the way for previously unattainable medical applications. In the coming years, we may see the emergence of virtual health assistants and advanced home-based healthcare, driven by the versatility of multimodal AI, revolutionizing the healthcare landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2ee449",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90027f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd3fd206",
   "metadata": {},
   "source": [
    "As artificial intelligence goes multimodal, medical applications multiply\n",
    "\n",
    "https://www.science.org/doi/10.1126/science.adk6139\n",
    "\n",
    "by Eric J. Topol\n",
    "\n",
    "15 Sep 2023\n",
    "\n",
    "Science Vol 381, Issue 6663\n",
    "\n",
    "\n",
    "As artificial intelligence (AI) continues to advance, its applications in the field of medicine are rapidly multiplying, thanks to its capabilities in multimodal data analysis. While machines lack the human ability to see, deep learning models have demonstrated their prowess in accurately interpreting various medical images, including X-rays, CT scans, MRI scans, pathology slides, and retinal photos. These AI-driven \"machine eyes\" not only rival human experts in image interpretation but also uncover features within medical images that are imperceptible to the human eye.\n",
    "\n",
    "For instance, a simple retinal scan, which appears as an image to human observers, contains a wealth of hidden information that machines can access. Through AI analysis, these scans can offer insights into a wide range of human physiological aspects, including blood pressure, glucose control, risks of diseases like Parkinson's, Alzheimer's, kidney ailments, hepatobiliary diseases, as well as the likelihood of heart attacks and strokes. This transformation in medical imaging represents a significant shift, enabling AI to play an increasingly pivotal role in healthcare.\n",
    "\n",
    "Cardiologists have witnessed the unexpected ability of AI to extract valuable insights from various medical data sources. For instance, AI-powered electrocardiogram (ECG) interpretation can now provide information about an individual's age, sex, anemia risk, diabetes risk, arrhythmia risk, heart function, valve disease, kidney health, and thyroid conditions. Similarly, the application of deep learning to pathology slides can yield crucial details about the origin of tumors, driver mutations, structural genomic variants, and prognosis.\n",
    "\n",
    "The progress achieved in image interpretation is largely attributed to supervised learning, which relies on fully annotated data inputs and ground truths. To move towards multimodal AI, the adoption of self-supervised and unsupervised learning methods was imperative. These approaches circumvented the laborious task of annotating vast datasets, which was infeasible given the scale of inputs required for AI models. The development of transformer model architectures, introduced in 2017 by Vaswani and colleagues, marked a pivotal step in this direction.\n",
    "\n",
    "Transformers are instrumental in surpassing the limitations of recurrent neural networks (RNNs) that depend on sequential feedback, such as word-by-word processing in a sentence. Transformers revolutionized AI by enabling models like GPT-4 to work with various data types, including text, audio, speech, and images. The training data for GPT-4 and other major base models did not include specific medical data but relied on sources like Wikipedia, the internet, and an extensive array of books. The incorporation of medical data for training would require supervised fine-tuning, which is currently under investigation for many healthcare use cases.\n",
    "\n",
    "Now that large language models (LLMs) have evolved into multimodal models, their capabilities extend far beyond text inputs and outputs. These models are not confined to a single mode of data but can seamlessly process text, audio, speech, and images. This expansion of functionality presents a challenge in appropriately naming these models, as their abilities span a wide spectrum. This complexity is further magnified when considering their potential applications in medicine, which are continually evolving and expanding.\n",
    "\n",
    "Multimodal AI has the capacity to leverage a plethora of data sources related to an individual's health. These sources include anatomical data from imaging, physiological biomarkers from sensors, genomic information, microbiome data, metabolomic profiles, immunological data, cellular-level transcriptomes, proteomic insights, and epigenetic markers. Electronic health records contribute lab results, family history, unstructured text, and long-term patient follow-up data to this rich tapestry of information. Additionally, data related to environmental factors, such as air pollution indices and other data gathered by environmental sensors, as well as social determinants, further enhance the depth of an individual's health profile. All of this can be supplemented by a vast repository of medical knowledge, which will increasingly become an integral part of LLMs utilized in future healthcare scenarios.\n",
    "\n",
    "This multimodal AI presents a wide array of data-driven applications across various healthcare domains. Individuals at risk of developing chronic medical conditions could benefit from virtual health assistants that provide continuous feedback on their health data. These assistants can help prevent or manage preexisting conditions by analyzing and coaching individuals based on their physical activity, sleep patterns, stress levels, retinal photos, unstructured medical records, and the latest medical literature. While virtual AI chatbot health assistants for specific conditions, such as diabetes, hypertension, obesity, and depression, already exist, they are yet to become holistic and preventive in nature.\n",
    "\n",
    "The integration of multimodal data has the potential to revolutionize remote monitoring, enabling a concept akin to a \"hospital-at-home.\" Continuous monitoring of vital signs, equivalent to an intensive care unit, can be performed remotely with algorithms designed to predict deterioration well before the onset of symptoms. This technology has the potential to reduce hospital admissions significantly, allowing patients to receive appropriate care without the need for physical hospitalization.\n",
    "\n",
    "Multimodal AI can also be employed in creating digital twins, which can provide personalized treatment plans for individuals diagnosed with various medical conditions. Additionally, it can play a crucial role in pandemic surveillance, offering real-time risk assessment for individuals based on factors like geolocation, wearable sensor data, symptoms, vaccination status, wastewater analysis, and more.\n",
    "\n",
    "While the early applications of large language models in healthcare have primarily focused on answering medical queries, reducing clinicians' administrative burdens, and even passing medical licensing exams, the advent of multimodal AI represents a more profound analytical challenge. Integrating and analyzing multiple layers of data from diverse sources, such as electronic health records and genomics, is a complex endeavor. This complexity emphasizes the substantial hurdles that must be overcome to unlock the full potential of multimodal AI in medicine.\n",
    "\n",
    "The challenges extend beyond the analytical domain. Large language models often exhibit overconfidence in their responses, potentially leading to erroneous conclusions. Concerns regarding biases, data privacy, data security, model performance degradation over time, regulatory approval criteria, resistance to change within medical practice, and the necessity for robust prospective evidence of benefit pose additional barriers to widespread adoption.\n",
    "\n",
    "The convergence of immense computational power and the ability to learn from extensive human-derived data has laid a solid foundation for realizing the exceptional potential of multimodal AI in healthcare. In the coming years, we can anticipate the emergence of virtual health assistants and \"hospital-at-home\" models that offer highly accurate and personalized healthcare approaches. While challenges remain, the promise of multimodal AI in medicine is undeniably transformative, paving the way for a new era of healthcare that is data-driven, personalized, and preventive.\n",
    "\n",
    "In closing, the article highlights the rapid progress of AI in healthcare and the ethical concerns it raises. While there have been significant advancements, the handling and resolution of these issues are still evolving. It is essential to ensure that healthcare professionals maintain critical thinking skills when using AI, establish robust data privacy measures, address biases in AI algorithms, prioritize transparency, and create mechanisms for accountability. Additional steps should involve standardizing AI protocols in healthcare, educating patients about AI's role, continuous monitoring of AI systems, interdisciplinary collaboration, and regulatory oversight to navigate the evolving ethical landscape effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae9322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
